---
title: "nla2012_waterchem"
author: "Bryan Milstead"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

## To Do
* redo the QA/QC checks
* make sure metadata are correct
* make sure the data can be spread
* `r paste("insult of the day:",bismer::insult())`

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

options(stringsAsFactors = FALSE) 
library(knitr)
library(tidyverse)
library(readxl)

read1<-function(dir='data/raw_data/',file='nla2012_waterchem_wide.csv'){
  a<-tryCatch(read.csv(paste(dir,file,sep=''),sep=',',na.strings = c(""," ","NA","N/A")),warning = function(e) read.csv(paste('../',dir,file,sep=''),sep=',',na.strings = c(""," ","NA","N/A")))
  return(a)
}  

names1<-function(df) names(df)[order(names(df))]
```

```{r formatData_function, include=FALSE}
#function to reformat the raw NLA data based on a modified data structure file
formatData<-function(x='nla2012_waterchem.csv',y='waterchem_nla2012.csv'){
#read the raw data; trycatch will look for the data in two directories
a<-tryCatch(read.csv(paste('data/raw_data/',x,sep=''),sep=',',na.strings = c(""," ","NA","N/A")),
            warning = function(e) read.csv(paste('../data/raw_data/',x,sep=''),sep=',',na.strings = c(""," ","NA","N/A")))

#get the modified data structure
struc<-tryCatch(read.csv(paste('data/workfiles/',y,sep=''),sep=',',na.strings = c(""," ","NA","N/A")),
            warning = function(e) read.csv(paste('../data/workfiles/',y,sep=''),sep=',',na.strings = c(""," ","NA","N/A")))

#choose columns to keep, gather, or delete
keeps<-filter(struc,parameter=='column_name')%>%select(DATA_COLUMN)%>% unlist(use.names = FALSE)
gathers<-filter(struc,parameter!='column_name',column_name!='delete')%>%select(DATA_COLUMN)%>%distinct()%>% unlist(use.names = FALSE)
deletes<-filter(struc,parameter=='delete')%>%select(DATA_COLUMN)%>% unlist(use.names = FALSE)

#gather 
wc<-gather(a,DATA_COLUMN,value,one_of(gathers))

#deconstruct the COLUMN_NAME (parameter)
  #df "struc" has the new row and column names
    #delete unwanted columns
a<-left_join(wc,struc)%>%select(-one_of(deletes))

#create new df based on descontructed column_name
v<-distinct(a,column_name)%>% unlist(use.names = FALSE)
ch<-select(a,one_of(keeps),parameter) %>% distinct()  #dim(waterchem) 1326 27

for(i in c(1:length(v))){
  w<-filter(a,column_name==v[i])%>%
    select(UID,parameter,value)
  names(w)[3]<-v[i]
  ch<-full_join(ch,w)
}

#change column names to snake case
names(ch)<-tolower(names(ch))

#add source
ch$source<-x

#output
return(list(ch,struc))
}
```

## Naming Conventions
* All variable names in lowercase
* use snake case for compound names (e.g., big_data)
* use parameter for the variable (e.g., NTL)
* use value for the measured value of the parameter

## Introduction

* This document ([nla2012_waterchem](https://github.com/willbmisled/lakes_database/blob/master/R/nla2012_waterchem.Rmd)) describes  converting the water chemistry data for the 2012 National Lakes Assessment from the wide format of the raw data files to a long format for database development.  For more information see [nla2012_master.rmd](https://github.com/willbmisled/lakes_database/blob/master/R/nla2012_master.Rmd).

* The output includes the following NLA 2012 datasets
    - waterchem
    - chla
    - algal toxins
    - atrazine
    - secchi
    - profile (partial: only the DO2_2M and temperature data are included)
    
* Four of these datasets (waterchem, chla, algal toxins, and atrazine) were processed in the same way:
    
    -  The original raw data files are in a wide format with two types of column names:
        - sample specific data: this includes things such as the UID (unique identifier for the sample), the LAB where the data were processed, and sample_ID.
        - parameter specific data: the names are complex variables indicating the a chemical parameter (e.g. COND=conductivity) and what is reported (e.g RESULT, UNITS, BATCH_ID, etc.).  
        
    - Not all of these data are useful to us but we will keep most of them just in case.  The final product may be pruned.
    
    - To support the conversion to a long format data structure files were created manually as csv files.  The structure files define which columns are "sample specic", which are "parameter specific" and which should be deleted.  They will be used to convert the paramater specific data to a long format while the sample specific data are kept in the wide format.  Confusing?

* The final two datasets secchi and profile deal with single parameters (secchi and DO2_2M). See details below
 

## Data Steps

* a function "formatData" was written to:
    - import the data and the structure file
    - reformat the data to a long format
* each dataset is reformatted and the general structure is defined
* datasets were combined into a single data.frame
* rearrange
* rename
* snake_case
    
### waterchem data

```{r waterchem, include=FALSE, echo=FALSE}
q<-formatData('nla2012_waterchem.csv','waterchem_nla2012.csv')
waterchem<-q[[1]]
struc_waterchem<-q[[2]]

#change nitrate_nitrite_n' units to 'mg N/L' (mostly correct but a few observation have units=='mg/l)'
waterchem<-mutate(waterchem,units=ifelse(parameter=='nitrate_nitrite_n',units=='mg N/L',units))
```

* The following table shows how the raw data will be deconstructed:
    - DATA_COLUMN: represents the original columns in the raw data
    - parameter:  in most cases this will be the parameter name in the new dataset except:
        - parameter=="column_name" indicates this column is sample specific so all unique observations will be kept
        - parameter=="delete" indicates this column will be deleted from the final data

```{r k_waterchem, include=TRUE, echo=FALSE}
kable(struc_waterchem)

```

* The waterchm dataset has the following columns (NOTE: some of these may be dropped or renamed in the final dataset):

```{r c_waterchem, include=TRUE, echo=FALSE}   
names1(waterchem)
```

* The following parameters are included as rows in the final dataset (NOTE: some of these may be dropped or renamed in the final dataset):
    
```{r p_waterchem, include=TRUE, echo=FALSE}  
unique(waterchem$parameter)
```

### chla

* Chlorophyll was measured in the littoral zone (CHLL) and the deep spot (CHLX) these parameters were renamed:
    - CHLL = 'chla_littoral'
    - CHLX = 'chla'
    
```{r chla, include=FALSE, echo=FALSE}
q<-formatData('nla2012_chla.csv','chla_nla2012.csv')
chla<-q[[1]]
struc_chla<-q[[2]]
```

* The following table shows how the raw data will be deconstructed:
    - DATA_COLUMN: represents the original columns in the raw data
    - parameter:  in most cases this will be the parameter name in the new dataset except:
        - parameter=="column_name" indicates this column is sample specific so all unique observations will be kept
        - parameter=="delete" indicates this column will be deleted from the final data

```{r k_chla, include=TRUE, echo=FALSE}
kable(struc_chla)
```

* The chla dataset has the following columns (NOTE: some of these may be dropped or renamed in the final dataset):

```{r c_chla, include=TRUE, echo=FALSE}   
names1(chla)
```

* The following parameters are included as rows in the final dataset (NOTE: some of these may be dropped or renamed in the final dataset):
    
```{r p_chla, include=TRUE, echo=FALSE}   
unique(chla$parameter)
```

### microcystin

* Microcystin was measured in the littoral zone (MICL) and the deep spot (MICX) these parameters will be renamed:
    - MICL = 'microcystin_littoral'
    - MICX = 'microcystin'
    
```{r mcl, include=FALSE, echo=FALSE}
q<-formatData('nla2012_algal_toxins.csv','algal_toxins_nla2012.csv')
mcl<-q[[1]]
struc_mcl<-q[[2]]
```

* The following table shows how the raw data will be deconstructed:
    - DATA_COLUMN: represents the original columns in the raw data
    - parameter:  in most cases this will be the parameter name in the new dataset except:
        - parameter=="column_name" indicates this column is sample specific so all unique observations will be kept
        - parameter=="delete" indicates this column will be deleted from the final data

```{r k_mcl, include=TRUE, echo=FALSE}
kable(struc_mcl)
```

* The mcl dataset has the following columns (NOTE: some of these may be dropped or renamed in the final dataset):

```{r c_mcl, include=TRUE, echo=FALSE}   
names1(mcl)
```

* The following parameters are included as rows in the final dataset (NOTE: some of these may be dropped or renamed in the final dataset):
    
```{r p_mcl, include=TRUE, echo=FALSE}   
unique(mcl$parameter)
```

### atrazine

```{r atrazine, include=FALSE, echo=FALSE}
q<-formatData('nla2012_atrazine.csv','atrazine_nla2012.csv')
atrazine<-q[[1]]
struc_atrazine<-q[[2]]
```

* The following table shows how the raw data will be deconstructed:
    - DATA_COLUMN: represents the original columns in the raw data
    - parameter:  in most cases this will be the parameter name in the new dataset except:
        - parameter=="column_name" indicates this column is sample specific so all unique observations will be kept
        - parameter=="delete" indicates this column will be deleted from the final data

```{r k_atrazine, include=TRUE, echo=FALSE}
kable(struc_atrazine)
```

* The atrazine dataset has the following columns (NOTE: some of these may be dropped or renamed in the final dataset):

```{r c_atrazine, include=TRUE, echo=FALSE}   
names1(atrazine)
```

* The following parameters are included as rows in the final dataset (NOTE: some of these may be dropped or renamed in the final dataset):
    
```{r p_atrazine, include=TRUE, echo=FALSE}   
unique(atrazine$parameter)
```

### secchi

```{r secchi, include=FALSE, echo=FALSE, eval=TRUE}
#read the raw data; trycatch will look for the data in two directories
secchi<-read1('data/raw_data/','nla2012_secchi.csv')

#add parameter and UNITS
secchi$parameter<-'secchi'
secchi$UNITS<-'m'

#rename and reorder
secchi<-select(secchi,uid=UID,parameter,result=SECCHI,units=UNITS,clear_to_bottom=CLEAR_TO_BOTTOM)

#clear to bottom
secchi$result[secchi$secchi_clear_to_bottom=='Y' & !is.na(secchi$clear_to_bottom)]<-NA

#add source
secchi$source<-'nla2012_secchi.csv'
```

* This dataset is mostly in the correct format.
* NOTE: changed all values for secchi to NA if CLEAR_TO_BOTTOM=='Y'
* Added: UNITS='m'
* The table below shows the columns that were added, deleted, or renamed.

```{r k_secchi, include=TRUE, echo=FALSE}
#get the modified data structure
struc_secchi<-tryCatch(read.csv('data/workfiles/secchi_nla2012.csv',sep=',',na.strings = c(""," ","NA","N/A")),warning = function(e) read.csv('../data/workfiles/secchi_nla2012.csv',sep=',',na.strings = c(""," ","NA","N/A")))
kable(struc_secchi)
```

### do2

* read the data from 'nla2012_profile.csv'
* There are 16955 rows in the do2 data that have UIDs but no SITE_IDs.  None of these UIDs is represented in the siteInfo so these were dropped.
* filter for !is.na(site_id)
* DO2_2M is their calculation of the average dissolved oxygen in the top 2 meters of the lake.  It is based on the profile data.
* harvest the NLA calculated do2_2m values for comparision
* calculate do2_2m from the profile data
    - note: the first observation (usually depth==0) was collected twice.  To avoid double counting we will calculate the mean do by depth then take the mean for the top 2m
* units='mg/l' was added 
* source='nla2012_profile.csv' added

### do2

```{r do2, include=FALSE, echo=FALSE, eval=TRUE}
#read the raw data; trycatch will look for the data in two directories
do2<-read1('data/raw_data/','nla2012_profile.csv')

#change column names to snake case
names(do2)<-tolower(names(do2))

#many observations with UIDs are missing SITE_ID
table(is.na(do2$site_id)) #F==13762 T==16955
nrow(filter(do2,!is.na(site_id))) #13762

#check if the UID's are in the info file
samples<-read1('output/','nla_samples.csv')

nrow(filter(do2, paste("2012_",uid,sep='')%in%samples$uid))  #13762
nrow(filter(do2,is.na(site_id))) #16955

#filter for !is.na(site_id)
do2<-filter(do2,!is.na(site_id)) #13762
nrow(select(do2,uid)%>%distinct()) #1230

#harvest the UID and DO2_2M fields; delete rows with is.na(do2$SITE_ID) and save for comparison to calculated values
    
do2old<-filter(do2,!is.na(do2_2m),!is.na(site_id))%>%select(uid,do2_2m)
nrow(do2old)  #1189

#calculate do2_2m
  #calculate mean do and temp by depth
profile <- group_by(do2, uid,depth)%>%
  summarise(oxygen=mean(oxygen, na.rm = TRUE),temperature=mean(temperature, na.rm = TRUE))%>%
    select(uid,depth,oxygen,temperature)
      nrow(profile) #11225

# filter for depth<=2m
do2<-filter(profile,depth<=2);nrow(do2) #3941

#calculate average do for depth<=2
do2 <- group_by(do2, uid)%>%
  summarise(result=mean(oxygen, na.rm = TRUE));nrow(do2) #1202

#delete rows for result==NA
do2<-filter(do2,!is.na(result));nrow(do2) #1190

#add UNITS='mg/l'
do2$units<-'mg/l'

#add parameter
do2$parameter<-'do2_2m'

#add source
do2$source<-'nla2012_profile.csv'

#compare
nrow(do2old) #1189
nrow(do2) #1190

test<-full_join(do2,do2old);nrow(test) #1190

test$dif<-abs(test$result-test$do2_2m)

filter(test,is.na(do2_2m)) #7164
filter(profile,uid==7164)
```
* compare the do2_2m calculated from the profile data (do2$result) and the NLA calculated value (do2old$do2_2m)
    - table below shows the results
* although the max is large the mean is small
* uid with large differences were visually inspected.  In these cases the calculated values were consistent with the data and the NLA values were not.  Some had irregularities in the profile depths (not consistent or even).
* The one missing value from the NLA is for uid==7164.  Data from only 2 depths below 2m were reported and these were for depths=c(1.49,1.69).  For now I'll leave this.


```{r do2a, include=TRUE, echo=FALSE, eval=TRUE}
summary(test$dif)
```

* a plot of the observed (result) and predicted values (do2_2m) shows that the results are fairly close
    - go with the calculated values 

```{r do2a, include=TRUE, echo=FALSE, eval=TRUE}
plot(test$do2_2m,test$result)
```

###temperature   

* the field water temperature data are in the profile dataset as "temperature" for multiple depths
* depths are not standardized so we'll calculate
- max_temp: max for the whole profile
- min_temp: min for the whole profile
- mean_temp: mean for the whole profile
- mean_temp_2m: mean for the DEPTH<=2 meters
* rbind all temp variables
* add units & source

```{r temp, include=FALSE,eval=TRUE}

# max_temp
max_temp<- group_by(profile, uid)%>%
  summarise(result=max(temperature, na.rm = TRUE))%>%
    filter(!is.na(result))
max_temp$parameter<-'temp_max'
max_temp #1200

# min_temp     
min_temp<- group_by(profile, uid)%>%
  summarise(result=min(temperature, na.rm = TRUE))%>%
    filter(!is.na(result))
min_temp$parameter<-'temp_min'
min_temp #1200

# mean_temp
mean_temp<- group_by(profile, uid)%>%
  summarise(result=mean(temperature, na.rm = TRUE))%>%
    filter(!is.na(result))
mean_temp$parameter<-'temp_mean'
mean_temp #1200

# mean_temp_2m
# filter for depth<=2m
profile2m<-filter(profile,depth<=2)%>%select(uid,temperature)

#calculate average do for depth<=2
mean_temp_2m<- group_by(profile2m, uid)%>%
  summarise(result=mean(temperature, na.rm = TRUE))%>%
    filter(!is.na(result))
mean_temp_2m$parameter<-'temp_2m'
mean_temp_2m #1200

#rbind temp variables
field_temp<-rbind(min_temp,max_temp,mean_temp,mean_temp_2m)

#add UNITS='degrees C'
field_temp$units<-'degrees C'

#add source
field_temp$source<-'nla2012_profile.csv'

```


* There are 16955 rows in the do2 data that have UIDs but no SITE_IDs.  None of these UIDs is represented in the siteInfo so these were dropped.
* Only the UID and DO2_2M columns are harvested from the profile dataset.
* DO2_2M is their calculation of the average dissolved oxygen in the top 2 meters of the lake.  It is based on the profile data.
* UNITS='mg/l' was added 


### join the datasets

* convert (if exist) fields RESULT, MDL, RL, and LOQ to numeric
* all files joined
* delete rows for result==NA
* add field duplicate=='P'; for the 2007 data there are primary and duplicate value; for consistency we'll add the same field to the 2012 data and set all values to P=primary.
* add "2012_" prefix to all uid 
* check that all uid are in 'nla_samples.csv' (TRUE)
* uid in 'nla_samples.csv' have STATUS=="Target_Sampled"

```{r join, include=FALSE, echo=FALSE,eval=TRUE}
waterchem<-mutate(waterchem,result=as.numeric(result),mdl=as.numeric(mdl),rl=as.numeric(rl))
chla<-mutate(chla,result=as.numeric(result),mdl=as.numeric(mdl),rl=as.numeric(rl))
atrazine<-mutate(atrazine,result=as.numeric(result),loq=as.numeric(loq),mdl=as.numeric(mdl))
mcl<-mutate(mcl,result=as.numeric(result),mdl=as.numeric(mdl),rl=as.numeric(rl))

chem2012<-bind_rows(waterchem,chla,mcl,atrazine,secchi,do2,field_temp)

chem2012$duplicate='P'

chem2012<-filter(chem2012,!is.na(result))

#add year prefix to uid
chem2012<-mutate(chem2012,uid=paste('2012_',uid,sep=''))

#check if the UID's are in the info file
nrow(chem2012) #40419
nrow(filter(chem2012, uid%in%samples$uid))  #40419

```

##QA/QC

* Two qa/qc checks were run on the chem data to make sure the data were assembled correctly.
- sums by parameter for the raw and final datasets were compared and were equal.
- sums by uid for the raw and final datasets were compared and were equal.
* checked sums for the waterchem data only; shows the process worked.

```{r qa, include=FALSE, echo=FALSE,eval=TRUE}
#get the raw data and change names to lowercase
a<-read1('data/raw_data/','nla2012_waterchem.csv') 

names(a)<-tolower(names(a))

#limit to the waterchem results
a<-a[,c(grep("uid",names(a)),grep("_result",names(a)))]

#rename to match parameters
names(a)<-sub("_result",'',names(a))

#update uid
raw<-mutate(a,uid=paste("2012_",uid,sep=''))

nrow(raw) #1230
nrow(select(chem2012,uid)%>%distinct()) #1230

#get raw sums
raw_sums<-apply(raw[,-1],2,sum,na.rm=TRUE)
raw_sums<-data.frame(parameter=names(raw_sums),raw_sums=raw_sums)

#get final sums 
final_sums<-group_by(chem2012, parameter)%>%summarise(sum=sum(result, na.rm = TRUE))

compare<-left_join(raw_sums,final_sums)%>%mutate(test=sum==raw_sums)
table(compare$test,useNA='ifany') #TRUE==22

#compare  sums by UID
#get sums by parameter for raw and chem2007
raw_sums1<-apply(raw[,-1],1,sum,na.rm=TRUE)
raw_sums1<-data.frame(uid=raw$uid,raw_sum=raw_sums1)


final1<-filter(chem2012,parameter%in%names(raw))
final_sums1<-group_by(final1, uid)%>%summarise(sum=sum(result, na.rm = TRUE))

compare1<-full_join(final_sums1,raw_sums1)%>%mutate(test=sum==raw_sum)
table(compare1$test,useNA='ifany') #TRUE==1228 NA==18; the falses are floating point errors
````

## Data definitions for the NLA2007 and NLA2012 chemistry data

* check that all column names are in 'nla_chem_data_defintions.csv' (TRUE)
* Below are the data definitions for column names of the chemistry data
* Included are four fields
    - **name**: is the column name (field)
    - **2007**: 1=field included in chem2007
    - **2012**: 1=field included in chem2012
    - **definition**: a brief description of the field 

```{r check_meta, include=FALSE, echo=FALSE,eval=TRUE}
#check that all names are in the dd file
dd<-read1('output/','nla_chem_data_defintions.csv')
 table(names(chem2012)%in%dd$name)
 #names(chem2012)[!names(chem2012)%in%dd$name]  #holding time is missing
 
 #filter(chem2012,!is.na(holding_time))%>%select(source)%>%distinct()
 
#check that all parameters are in the pd file
table(unique(chem2012$parameter)%in%pd$parameter)
filter(chem2012,!parameter%in%pd$parameter)%>%select(parameter,source)%>%distinct()
```

```{r data_defintions, include=TRUE, echo=FALSE,eval=TRUE}
kable(dd)
```

* check that all parameters are in 'nla_chem_data_paramters.csv' (TRUE)
* The following table defines the parameters in the chem data
* This table has six fields
    - **parameter**: the name of the chemical analyte or measurement 
    - **name07**: the original name for the parameter in the NLA2007 data (if measured)
    - **name12**: the original name for the parameter in the NLA2012 data (if measured)
    - **units07**: the measurement units for the parameter in the NLA2007 data 
    - **units12**: the measurement units for the parameter in the NLA2012 data 
    - **definition**: a brief description of the parameter 
    
```{r param_defintions, include=TRUE, echo=FALSE,eval=TRUE}



kable(pd)
```
## spread check
* make sure the data can be "spread"; works

```{r spread, include=FALSE, echo=FALSE,eval=TRUE,eval=TRUE}
spread<-select(chem2012,uid,duplicate,parameter,result)%>%
  spread(parameter,result)
nrow(spread) #1230

```

## Save the data

* chem2012 saved as 'output/nla2012_chem.csv'

```{r save, include=FALSE, echo=FALSE,eval=TRUE}
tryCatch(write.table(chem2012,'output/nla2012_chem.csv',sep=',',row.names=FALSE),warning = function(e) write.table(chem2012,'../output/nla2012_chem.csv',sep=',',row.names=FALSE))
```



